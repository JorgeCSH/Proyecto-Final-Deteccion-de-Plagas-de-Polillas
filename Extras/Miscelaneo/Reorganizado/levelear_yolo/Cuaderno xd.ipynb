{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "> # Cuaderno para Yolo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "> ## Sobre este documento\n",
    "> En este notebook que claramente no tiene errores ortográficos están los apuntes que tome mientras estudiaba como utilizar _Yolo_. Si se ve que los codigos son medio exoticos, fue para evitar que mi laptop explote, por lo que decidi anotar los codigos por separados para no ejecutar todo por accidente a cada rato (xd). Igual agregué el codigo para ejecutar pero con un \"#\" como medida de emergencia.\n",
    ">\n",
    "> La gracia es poder dividirlo en capitulos donde están anotaciones que fui haciendo, estas pueden presentar errores y no me hago responsable por eso.\n",
    ">\n",
    "> La mayor inspiracion fue los videos oficiales que se encuentran en la página de [Ultralitycs](https://docs.ultralytics.com), además de los videos que fuimos encontrando y, de ser necesario, otras páginas que se agregara su respectiva procedencia cuando sea necesario.\n",
    ">\n",
    "> Cualquier error ortográfico tiene su ~~chamullo~~ argumento en que no realize el notebook en google colab, si bien idealmente ya debería de haber arreglado esto, puede que se escape alguno.\n",
    "\n",
    "> ## Indice:\n",
    "> ### - __$\\text{I}$__ ............... Las Bases\n",
    "> ### -__$\\text{II}$__ ............... Prediccion"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ## I. Las Bases\n",
    "\n",
    "> Para esta seccion ($\\text{I}$) se consideran que hacer al iniciar un archivo o utilizar yolo por primera vez.\n",
    "> ### I.1 Iniciar\n",
    "> #### Instalar Ultralitycs\n",
    "> El siguiente codigo permite instalar la libreria de __Ultralytics__ que permite trabajar con __Yolov8__, además de un poco de información extra sobre el hardware utilizado.\n",
    "> ``` python\n",
    "> !nvidia-smi                 # Para ver info sobre la tarjeta de video (no se si funciona si no se es nvidia)\n",
    "> !pip install ultralytics    # Instala Ultralytics, libreria con Yolo\n",
    "> ```\n",
    "> #### Obtener Yolov8\n",
    "> Para obtener _Yolo_ como tal, basta con ejecutar el (los) siguientes comandos (todos de una).\n",
    "> ``` python\n",
    "> from ultralytics import YOLO                    # Obtiene Yolo\n",
    "> import os                                       # -|\n",
    "> from IPython.display import display, Image      #  |    | Un monton de cosas que no se que hacen\n",
    "> from IPython import display                     #  |--> | Permite filtrar el \"modelo\" de Yolo que se quiere\n",
    "> display.clear_output()                          #  |    | Tampoco se que significa\n",
    "> !yolo mode=checks                               # -|\n",
    "> ```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-31T20:44:25.709605Z",
     "start_time": "2023-10-31T20:44:25.700629400Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install ultralytics       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#from ultralytics import YOLO                    \n",
    "#import os                                       \n",
    "#from IPython.display import display, Image      \n",
    "#from IPython import display                     \n",
    "#display.clear_output()                          \n",
    "#!yolo mode=checks                               "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T20:44:25.723567800Z",
     "start_time": "2023-10-31T20:44:25.710602800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ### I.2 Manejo del dataset\n",
    "> #### Obtencion de un dataset\n",
    "> Hay unas cuantas formas, la primera que me gustaría destacar es usando una herramienta llamada [Roboflow](https://roboflow.com/) donde se pueden, entre diversas (creo) funciones, obtener dataset prehechos o compilar datasets propios. Usando este sistema te devolveria un codigo en formato _Yolov8_ (opcion que tienes que seleccionar cuando te la pida) que permite obtener el dataset.\n",
    "> #### Etiquetado\n",
    "> [Roboflow permite etiquetar](https://app.roboflow.com/modulo/moths-moths-everywhere/2) y crear datasets con base en images, las cuales uno tiene que identificar despues manualmente. Esto permite obtener un dataset como el previamente nombrado pero de propio. Cuidado, creo que hay una opcion para entrenar, solo hay tres creditos para usarla (aunque no se si debemos usar eso).\n",
    ">\n",
    "> De manera general, un dataset exportado de esta manera podría verse de la forma (un dataset de dos imagenes que hice jeje)...\n",
    "> ```python\n",
    "> !pip install roboflow\n",
    ">\n",
    "> from roboflow import Roboflow\n",
    "> rf = Roboflow(api_key=\"a1Jrm76gYvcph3DjNjm3\")\n",
    "> project = rf.workspace(\"modulo\").project(\"moths-moths-everywhere\")\n",
    "> dataset = project.version(2).download(\"yolov8\")\n",
    "> ```\n",
    "> Aunque de ser necesario se podría usar otra forma (?), esto queda propuesto como ejercicio para el lector. Este dataset se descargaría en el sistema o colab, dependiendo de donde se use.\n",
    "Cabe destacar que de esta forma también podemos diferenciar entre archivos que se usaran para entrenar, validar y testear, asi que hay para divertirse con el menu de images que se obtengan."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#!pip install roboflow\n",
    "\n",
    "#from roboflow import Roboflow\n",
    "#rf = Roboflow(api_key=\"a1Jrm76gYvcph3DjNjm3\")\n",
    "#project = rf.workspace(\"modulo\").project(\"moths-moths-everywhere\")\n",
    "#dataset = project.version(2).download(\"yolov8\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T20:44:25.742517Z",
     "start_time": "2023-10-31T20:44:25.723567800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ### I.3 Entrenamiento del Dataset\n",
    "> Con el dataset y usando el comando otorgado por _Yolov8_...\n",
    "> ```python\n",
    "> !yolo task=detect mode=train model=yolov8m.pt data={dataset.location}/data.yaml epochs=20 imgsz=640\n",
    "> ```\n",
    "> Donde este codigo~~claramente no copiado~~ sigue la siguiente configuracion:\n",
    "> * __task__: tarea que buscamos hacer; task=detect $\\implies$ deteccion de objetos.\n",
    "> * __mode__: como se realiza; mode=train $\\implies$ entrenar nuestro propio modelo en Yolov8 para realizar task.\n",
    "> * __model__: version de yolo; model=yolov8m.pt $\\implies$ yolo version medio (claramente se que es \\s).\n",
    "> * __data__: locacion del dataset; data={dataset.location}/data.yaml $\\implies$ locacion del dataset que tiene que editarse un poco en colab.\n",
    "> * __epochs__: cantidad de veces que se ejecuta un loop del dataset; epochs=20 $\\implies$ se ejecuta el loop un total de 20 vecez del dataset dado (~~pc goes BROOOOOOM~~)\n",
    "> * __imgsz__: tamano de la imagen; imgsz=640 $\\implies$ imagen de tamano 640 (asumo que pixeles (?))\n",
    "> El resultado del entrenamiento arrojara los pesos que se pueden obtener directamente en el google colab."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#!yolo task=detect mode=train model=yolov8m.pt data={dataset.location}/data.yaml epochs=3 imgsz=640"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T20:44:25.759472400Z",
     "start_time": "2023-10-31T20:44:25.741519100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ### I.4 Informacion de Resultados\n",
    "> Existen algunas herramientas que sirven para un analisis más tecnico de los resultados, como una matriz de confusion para representar como se fue realizando la deteccion y ver asi si se asociaron los caracteres respectivos de cada imagen (una matriz diagonal es mejor). Mi habilidad para explicarlo no es tan buena, pero viéndola se entiende que informacion busca darte.\n",
    "> ```python\n",
    "> Image(filename=nombre'direccion/de el/archivo.png', width=tamano)\n",
    "> ```\n",
    "> O también un set de gráficos que entrega datos sobre el entrenamiento y el resultado comparando con un desarrollo ideal o \"smooth\", que significa cada gráfico está fuera de mi alcance para el momento que escribo este notebook.\n",
    "> ```python\n",
    "> Image(filename=nombre'direccion/de el/archivo.png', width=tamano)\n",
    "> ```\n",
    ">\n",
    "> Para validar los datos con (valga la redundancia) datos no usados previamente, usamos el codigo de yolo...\n",
    "> ```python\n",
    "> !yolo task=detect mode=val model/content/runs/detect/train/weights/best.pt data={dataset.location}/data.yaml\n",
    "> ```\n",
    ">\n",
    "> Finalmente, una prediccion se ejecuta y visualiza mediante los codigos...\n",
    "> ```python\n",
    "> !yolo task=detect mode=predict model=/content/runs/detect/train/weights/best.pt conf=0.5 source={dataset.location}/\n",
    "> ```\n",
    "> ```python\n",
    "> import glob\n",
    "> from IPython.display import Image, display\n",
    ">\n",
    "> for image_path in glob.glob(f'/content/runs/detect/predict/*.jpg'):\n",
    ">    display(Image(filename=image_path, height=600))\n",
    ">    print(\"\\n\")\n",
    "> ```\n",
    "> Este último ejecutandose para todas las imagenes en la carpeta que contiene datos para predecir y detectar."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## II. Prediccion"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para esta seccion ($\\text{II}$) se buscara obtener, o mejor dicho extraer los resultados y la informacion arrojada por el entrenamiento.\n",
    "\n",
    "### II.1 Resultados\n",
    "Yolo permite extraer resultados que vienen dados por un objeto el cual contiene un \"pytorch tensor\" que permite ver los resultados. Es importante mencionar que para visualizar los resultados sera necesario transformar o pasar a la cpu los resultados de la gpu, para lo cual se aplica el(los) siguiente(s) codigo(s):\n",
    "```python\n",
    "results = results.cuda()\n",
    "results = results.cpu()\n",
    "results = results.to('cpu')\n",
    "results = results.numpy() \n",
    "```\n",
    "Los cuales transforman los transforman los resultados a eleccion (cuda=gpu,  cpu=cpu, to=tu eliges, numpy=formato numpy).\n",
    "\n",
    "Los resultados pueden ser de diferentes tipos a elegir, para lo cual se tiene el objeto Results que permite manipular en con propiedades a eleccion. Esto es para cajas encerrantes (bounding boxes), mascaras, puntos claves, probabilidades (una clase) o una direccion.\n",
    "```python\n",
    "Result.boxes\n",
    "Result.mask\n",
    "Result.keypoints\n",
    "Result.probs\n",
    "Result.orig_img\n",
    "Result.path\n",
    "```\n",
    "Para cada caracteristica, [aqui](https://docs.ultralytics.com/modes/predict/) encontraras toda la informacion oficial de como manipularlas en caso de que no sea tratado aqui.\n",
    "### II.2 Clase deteccion de objetos\n",
    "El hecho de definir una clase es inspiracion de la documentacion, sin embargo sirve para trabajar con estos objetos.\n",
    "En una clase podemos trabajar realizando los mismos procesos anteriores, agregando la extracion de los resultados. Para esto y omitiendo todo el resto de la clase (xd) y considerando los resultados trabajados como bounding boxes, se puede definir una funcion de la forma...\n",
    "```python\n",
    "    def plot_boundingboxes(self, results, frame):\n",
    "        xyxys = []\n",
    "        confidence = []\n",
    "        class_ids = []\n",
    "\n",
    "        # Extraer deteccion\n",
    "        for result in results:\n",
    "            boxes = result.boxes.cpu().numpy()\n",
    "            print(format)\n",
    "        \n",
    "        return frame\n",
    "```\n",
    "La gracia es que toma los objetos y devuelve un resultado trabajado como boxes que se transformo en la cpu y numpy, estos son printeados en la consola de comandos. \n",
    "\n",
    "La creacion de estas clases es extensa y con mucha informacion a la vez, por ende para optimizar se agrego un [link](https://github.com/niconielsen32/YOLOv8-Class/blob/main/YOLOv8InferenceClass.py) a un codigo con una clase [~~no robada~~](https://www.youtube.com/watch?v=QtsI0TnwDZs&ab_channel=Ultralytics) para poder ver el funcionamiento."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
